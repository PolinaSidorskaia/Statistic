#         1.Case A.

data <- data.frame(score = c(56,61,68,51,55,67,66,67,55,71,77,78,35,65,81,77,62,78),group = c(rep('pre', 9), rep('post', 9)))
data

library(dplyr)

#найти размер выборки, среднее значение и стандартное отклонение для каждой группы
data %>%
  group_by(group) %>%
  summarise (
    count = n(),
    mean = mean(score),
    sd = sd(score))

boxplot(score~group,
        data=data,
        main="Test Scores by Group",
        xlab="Group",
        ylab="Score",
        col="steelblue",
        border="black") 
#Как по сводной статистике, так и по диаграммам мы видим, что средний балл в пост -группе намного выше, чем средний балл в предварительной группе. Мы также можем видеть, что оценки для пост -группы имеют большую изменчивость, чем оценки в предварительной группе.

#Чтобы выяснить, является ли разница между средними значениями для этих двух групп статистически значимой, мы можем приступить к проведению парного t-теста.


#Прежде чем проводить парный t-критерий, мы должны проверить, что распределение различий нормально (или приблизительно нормально) распределено. Для этого мы можем создать новый вектор, определяемый как разница между оценками до и после, и выполнить тест Шапиро-Уилка на нормальность этого вектора значений:

#определите новый вектор для разницы между результатами после и до оценки
differences <- with(data, score[group == "post"] - score[group == "pre"])

#выполните тест Шапиро-Уилка на нормальность для этого вектора значений
shapiro.test(differences)


#Значение p теста составляет 0.088, что больше, чем альфа = 0,05. Поскольку это p-значение не меньше нашего уровня значимости α = 0,05, мы не можем отвергнуть нулевую гипотезу(что различий нет). Различия могут быть.


t.test (score ~ group, data = data, paired = TRUE)

#Из вывода мы видим, что:

#Тестовая статистика t равна 2.1857 .
#Значение p для этой тестовой статистики с 8 степенями свободы(df) равно 0.06032 .
#95% доверительный интервал для средней разницы составляет (-0.4769297, 17.8102630) .
#Средняя разница между баллами для группы до и после лечения составляет 8.66 .

# p-value < 0,1 означает, что нулевая гипотеза кажется не верной, и результат может быть статистически значимым. 

#у нас достаточно доказательств, чтобы сказать, что средние баллы между группами до и после обучения статистически значимо различаются. Это означает, что учебная программа оказала существенного влияния на результаты тестов.

#Однако, наш доверительный интервал 95% говорит о том, что мы «уверены на 95%» в том, что истинная средняя разница между двумя группами находится между -0.4769 и 17.8102

#Поскольку в этом доверительном интервале содержится нулевое значение, это означает, что ноль на самом деле может быть истинной разницей между средними баллами, поэтому в данном случае нам не удалось однозначно отвергнуть нулевую гипотезу.


#    Case B. 

wolf <- read.csv ("date/InbreedingWolves.csv", sep = ",",  header = TRUE)


library (stringr)
wolf [c('inbreeding.coefficient', 'pups')] <- str_split_fixed(wolf$inbreeding.coefficient.pups, ';', 2)

wolf <- subset(wolf, select = - c(inbreeding.coefficient.pups))
head(wolf)

library(ggplot2)
## Строим график
wolf_plot <- ggplot(data = wolf, aes(y=pups, x=inbreeding.coefficient))+
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue")+
  labs(x = 'Коэф.инбридинга', y = 'Кол-во щенков') +
  theme_bw()
wolf_plot


#Вычисление коэффициента корреляции

class(wolf$inbreeding.coefficient)
class(wolf$pups)


a <- as.numeric(unlist(wolf$inbreeding.coefficient))
b <-as.numeric(unlist(wolf$pups))

cor.test(x=a,y=b, method = "pearson", alternative = "two.sided")

# Коэффициент корреляции между двумя векторами оказывается равным -0.6. Наблюдается отрицательная корреляция. Сильная отрицательная линейная зависимость.

#p-значение, связанное с t = -3.5893 и степенями свободы df = 22, составляет 0.001633 .Поскольку это p-значение меньше нашего уровня значимости α = 0,05 / 0.1 , мы отвергаем нулевую гипотезу (что связи нет). Это позволяет предположить, что существует значительная корреляция между коэффициентами инбридинга и количеством детенышей.

# В данном случае использовался коэф.Пирсона - Оценивает связь двух нормально распределенных величин. Выявляет только линейную составляющую взаимосвязи.
#Коэффициент корреляции — это статистика, значение которой описывает степень взаимосвязи двух сопряженных переменных. 


wolf_model <- lm(b ~ a)
summary(wolf_model)

coefficients(wolf_model)

#Прогнозируемое количество щенков с коэф.инбридинга 0
#      6.567221 - 11.446674 * 0 = 6.5 (похожий результат на графике)



#                                            Case C. 

library (DescTools)
df <- data.frame(Patient = rep (1:12, each = 2 ),
                 meet = rep(c('1st meeting', 'One month later'), times = 12),
                 outcome = c(0,1,0,1,1,1,0,0,0,1,0,0,1,0,0,1,0,1,1,1,0,0,0,1))
CochranQTest(outcome ~ meet| Patient, data=df)



#По результатам теста мы можем наблюдать следующее:

#Статистика теста Q = 3.5714
#Соответствующее значение p равно 0.05878

#Тестовая статистика Q соответствует распределению хи-квадрат с k-1 степенями свободы.

#Поскольку это p-значение меньше 0,1, мы можем отвергнуть нулевую гипотезу. Это означает, что у нас достаточно доказательств, чтобы сказать, что количество соблюдающих режим приема лекарств увеличился.


#                          Case D. 

#  В этом кейсе я сравнила 3 группы между собой. Я попыталась сделать как в задании, но не очень получилось.


#Isolated - A
#CompanionNotInjected - B
#CompanionInjected - C

data_D <- data.frame(stretching = c(46.7, 38.9, 65.6, 35.6, 32.2, 30.0, 41.1, 63.3, 0.0, 53.3, 22.2, 48.9, 5.6, 14.4, 46.7, 45.6, 42.2 ,
                                    56.7, 51.1, 50.0, 51.1, 44.4, 2.2, 41.1, 33.3, 25.6, 22.2, 14.4, 3.3, 64.4 ,
                                    36.7, 81.1, 66.7, 66.7, 44.4, 54.4, 63.3, 62.2, 58.9, 50.0, 54.4, 57.8),group = c(rep('A', 17), rep('B', 13), rep ('C', 12)), several = c(42.6))

boxplot(stretching ~ group,
        data = data_D)

#Только из этих диаграмм видно что "“stretching” behavior " больше проявляется в группе с соседом, который уже испытывал боль. Между группами где мышь была изолирована и где имела обычного соседа, разброс значений больше в группе В - CompanionNotInjected, однако среднее значения "stretching" одинаково

model <- aov(stretching ~ group,
             data = data_D)
summary(model)
#Из данной модели мы видим что, что группы статистически значимы Pr(>F) = 0.00322 меньше 0.05.

#мы должны проверить, выполняются ли предположения нашей модели, чтобы наши результаты из модели были надежными.

plot(model) 

#Приведенный график QQ позволяет нам проверить предположение о нормальности. В идеале стандартизированные остатки должны располагаться вдоль прямой диагональной линии на графике. Однако на графике выше мы видим, что остатки немного отклоняются от линии к началу и концу. Это указывает на то, что наше предположение о нормальности может быть нарушено.

#Приведенный выше график «Остатки против подобранных » позволяет нам проверить наше предположение о равных дисперсиях. В идеале мы хотели бы, чтобы остатки были равномерно распределены для каждого уровня подобранных значений.Мы видим, что остатки гораздо более разбросаны для более высоких подогнанных значений, что указывает на то, что наше предположение о равных дисперсиях может быть нарушено.



#Как только мы убедимся, что допущения модели выполняются (или разумно выполняются), мы можем провести апостериорный тест , чтобы точно определить, какие группы лечения отличаются друг от друга.

#Для нашего апостериорного теста мы будем использовать функцию TukeyHSD() для проведения теста Тьюки для множественных сравнений:

TukeyHSD(model, conf.level=.95)

#Значение р указывает, есть ли статистически значимая разница между каждой программой. Из результатов видно, что существует статистически значимая разница между "значением сочувствия" по каждой группе на уровне значимости 0,05, кроме группы В( изолированными и с обычным соседом). Такой же вывод мы сделали из boxplot.



plot(TukeyHSD(model, conf.level=.95), las = 2)

#Результаты доверительных интервалов согласуются с результатами проверки гипотез.

#В частности, мы видим, что один из доверительных интервалов для значений "сочувствия" между группами  содержит нулевое значение, что указывает на наличие статистически не значимой разницы в "сочувствии" между группами изолированных и с обычным соседом.Это согласуется с рассчитанными р-значениями.

# В группе где испытуемого поместили с соседом, который ранее испытывал боль, оный проявляет больше сочувствия нежели в группе, где сосед не испытывал той же боли, однако разброс значений больше но не выше.



#################################################################################################### Пыталась построить модели зависимости
data <- data.frame(Isolated = c(46.7, 38.9, 65.6, 35.6, 32.2, 30.0, 41.1, 63.3, 0.0, 53.3, 22.2, 48.9, 5.6, 14.4, 46.7, 45.6, 42.2) , CompanionNotInjected = c(56.7, 51.1, 50.0, 51.1, 44.4, 2.2, 41.1, 33.3, 25.6, 22.2, 14.4, 3.3, 64.4, NA,NA,NA,NA) , CompanionInjected = c(36.7, 81.1, 66.7, 66.7, 44.4, 54.4, 63.3, 62.2, 58.9, 50.0, 54.4, 57.8, NA, NA, NA,NA,NA))


head(data)
str(data)

ggplot(data, aes(y = 1:nrow(data), x = Isolated  )) + geom_point() +
  labs(y = 'Порядковый номер \nв датасете', x = 'Значения переменной')


gg_dot <- ggplot(data, aes(y = 1:nrow(data))) + geom_point() + ylab('index')
Pl1 <- gg_dot + aes(x = Isolated )
Pl2 <- gg_dot + aes(x = CompanionNotInjected)
Pl3 <- gg_dot + aes(x = CompanionInjected)


library(cowplot) # пакет для группировки графиков
theme_set(theme_bw())
plot_grid(Pl1, Pl2, Pl3, ncol = 3, nrow = 3)


library(car)
pairs(data)

#Полная модель. stretching = b0 + b1 * Isolated + b2 * Companion not injected + b3 * Companion injected + ε

#Нулевая модель: stretching = b0 + ε




#                        Case E.


data_E <- read.csv ("date/prostate.data", sep = "\t",  header = TRUE)
head(data_E)
print(cor(data_E))
# Показывает только значения коррелиции. Однако можно заметить что lcavol, lweight и age положительно коррелируются с lpsa. 

#Результат равен 0, если между двумя переменными нет корреляции
#Результат равен 1, если между двумя переменными есть положительная корреляция
#Результат равен -1, если между двумя переменными имеется отрицательная корреляция

#Обычная корреляция не учитывает, что взаимосвязь между переменными может находиться под контролем других переменных и их взаимодействий.
#Множественные тесты. При тестировании значимости множества коэффициентов корреляции нужно вводить поправку для уровня значимости. Лучше было бы учесть все в одном анализе.



data_E <- subset(data_E, select = - c(X))  # Удаляем Х - его не нужно учитывать
head(data_E)


library(ggplot2)

data_E_2 <- data_E


ggplot(data_E_2, aes(y = 1:nrow(data_E), x = lpsa  )) + geom_point() +
  labs(y = 'Порядковый номер \nв датасете', x = 'Значения переменной')


gg_dot <- ggplot(data_E, aes(y = 1:nrow(data_E))) + geom_point() + ylab('index')
Pl1 <- gg_dot + aes(x = lpsa)
Pl2 <- gg_dot + aes(x = lcavol)
Pl3 <- gg_dot + aes(x = lweight)
Pl4 <- gg_dot + aes(x = age)
Pl5 <- gg_dot + aes(x = lbph)
Pl6 <- gg_dot + aes(x = svi)
Pl7 <- gg_dot + aes(x = lcp)
Pl8 <- gg_dot + aes(x = gleason)
Pl9 <- gg_dot + aes(x = pgg45)

library(cowplot) # пакет для группировки графиков
theme_set(theme_bw())
plot_grid(Pl1, Pl2, Pl3, Pl4, Pl5, Pl6,
          Pl7,Pl8, Pl9, ncol = 4, nrow = 4)


#Нам предстоит построить модель множественной линейной регрессии. Для случая с одним предиктором yi=b0+b1x1i+ei— линия регрессии

#Для случая с двумя предикторами yi=b0+b1x1i+b2x2i+ei — плоскость в трехмерном пространстве

#Для случая с большим количеством предикторов yi=b0+b1x1i+b2x2i+b3x3i+...+bp−1xp−1i+ei Плоскость в n-мерном пространстве, оси которого образованы значениями предикторов

#Знакомство с данными

library(car)
pairs(data_E)

#Полная модель. lpsa = b0 + b1*lcavol+b2*lweight+b3*age+b4*lbph+b5*svi+b6*lcp+b7*gleason+b8*pgg45Ti+ei

mod=lm(lpsa~lcavol+lweight+age+lbph+svi+lcp+gleason+pgg45,data=data_E)

summary(mod)

#Мультиколлинеарность — наличие линейной зависимости между независимыми переменными (предикторами) в регрессионной модели.

#При наличии мультиколлинеарности оценки параметров неточны, а значит сложно интерпретировать влияние предикторов на отклик.

#В случае наличия мультиколлинеарности:
  
#  Оценки коэффициентов модели нестабильны (даже могут менять знак при небольших изменениях модели или исходных данных).
#Стандартные ошибки оценок параметров увеличатся в √VIF раз.
#В результате меньше шансов заметить влияние предиктора, т.к. уровень значимости (p-value) в тестах будет выше.

# Проверяем, есть ли коллинеарность?
vif(mod)

#Можно последовательно удалить из модели избыточные предикторы с VIF > 2
#1подбираем модель
#2считаем VIF
#3удаляем предиктор с самым большим VIF
#4повторяем 1-3

# - lcp  
mod1=lm(lpsa~lcavol+lweight+age+lbph+svi+gleason+pgg45,data=data_E)
vif(mod1)

# - pgg45  
mod2=lm(lpsa~lcavol+lweight+age+lbph+svi+gleason,data=data_E)
vif(mod2)

#Теперь мультиколлинеарности нет. В модели осталось 6 предикторов (и 7 параметров).

#Уравнение модели
coef(mod2)

# lpsa= -0.2 + 0.5*lcavol+0.6*lweight-0.02*age+0.09*lbph+0.7*svi+0.1*gleason


#Модельная матрица в множественной регрессии. Аналогично простой регрессии Y=Xb+e Отличие лишь в форме модельной матрицы

X <- model.matrix(mod2)
head(X)

summary(mod2)
anova(mod2)


# - gleason  
mod3=lm(lpsa~lcavol+lweight+age+lbph+svi,data=data_E)
vif(mod3)

summary(mod3)
anova(mod3)

# - age  
mod4=lm(lpsa~lcavol+lweight+lbph+svi,data=data_E)
summary(mod4)
anova(mod4)

# - lbph  
mod5=lm(lpsa~lcavol+lweight+svi,data=data_E)
summary(mod5)
anova(mod5)


#Частный F-критерий при помощи drop1() (шаг 1)
#Тестируем значимость всех предикторов за один раз. Затем выбираем предиктор, удаление которого меньше всего ухудшает модель.

drop1(mod5, test = "F")

#Квантильный график остатков
library(car)
qqPlot(mod5)
#Отклонения от нормального распределения остатков незначительны


#1) График расстояния Кука
#Выбросов нет
mod5_diag <- data.frame(
  fortify(mod5), 
  data_E[, c("gleason", "age", "lbph")]
)

ggplot(mod5_diag, aes(x = 1:nrow(mod5_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")

#2) График остатков от предсказанных значений
#Выбросов нет
#Гетерогенность дисперсии? 
gg_resid <- ggplot(data = mod5_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid


#3) Код для графиков остатков от предикторов в модели и нет

res_1 <- gg_resid  + aes(x = lpsa)
res_2 <- gg_resid  + aes(x = lcavol)
res_3 <- gg_resid  + aes(x = lweight)
res_4 <- gg_resid  + aes(x = age)
res_5 <- gg_resid  + aes(x = lbph)
res_6 <- gg_resid  + aes(x = svi)
res_8 <- gg_resid  + aes(x = gleason)
res_9 <- gg_resid  + aes(x = pgg45)


library(gridExtra)
grid.arrange(res_1, res_2, res_3,
            res_6, nrow = 2)

# Для улучшения модели следует также убрать svi значение.

mod6=lm(lpsa~lcavol+lweight,data=data_E)
summary(mod6)
anova(mod6)


#Частный F-критерий при помощи drop1() (шаг 1)
#Тестируем значимость всех предикторов за один раз. Затем выбираем предиктор, удаление которого меньше всего ухудшает модель.

drop1(mod6, test = "F")
drop1(mod, test = "F")

#1) График расстояния Кука
#Выбросов нет
mod6_diag <- data.frame(
  fortify(mod6), 
  data_E[, c("gleason", "age", "lbph", "svi")]
)

ggplot(mod5_diag, aes(x = 1:nrow(mod6_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")

#2) График остатков от предсказанных значений
#Выбросов нет

gg_resid <- ggplot(data = mod6_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid


#3) Код для графиков остатков от предикторов в модели и нет

res_1 <- gg_resid  + aes(x = lpsa)
res_2 <- gg_resid  + aes(x = lcavol)
res_3 <- gg_resid  + aes(x = lweight)
res_4 <- gg_resid  + aes(x = age)
res_5 <- gg_resid  + aes(x = lbph)
res_6 <- gg_resid  + aes(x = svi)
res_8 <- gg_resid  + aes(x = gleason)
res_9 <- gg_resid  + aes(x = pgg45)


library(gridExtra)
grid.arrange(res_1, res_2, res_3,
              nrow = 2)


#4)Квантильный график остатков
library(car)
qqPlot(mod6)
#Отклонения от нормального распределения остатков незначительны



summary(mod6)

# Данная модель является наилучшей с сильными связями между предикторами. p-value - очень маленькое.

anova(mod, mod6)

#H0 (нулевая гипотеза): все предикторы равно-значимы
#HA (альтернативная гипотеза): есть хотя бы одно значение имеющее большее значение

#Поскольку значение p в нашей таблице ANOVA (0.01119) меньше 0,05, у нас есть достаточно доказательств, чтобы отклонить нулевую гипотезу.



summary(mod) # lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45
#Adjusted R-squared:  0.6328 
 #   Multiple R-squared:  0.6634

summary(mod1)#- lcp # lpsa ~ lcavol + lweight + age + lbph + svi + gleason + pgg45
#Adjusted R-squared:  0.6312
 #   Multiple R-squared:  0.6581

summary(mod2)#- lcp-pgg45  # lpsa ~ lcavol + lweight + age + lbph + svi + gleason
#Adjusted R-squared:  0.6334
 #   Multiple R-squared:  0.6563

summary(mod3)#- lcp-pgg45-gleason  # lpsa ~ lcavol + lweight + age + lbph + svi
#Adjusted R-squared:  0.6335
 #   Multiple R-squared:  0.6526

summary(mod4)#- lcp-pgg45-gleason-age #lpsa ~ lcavol + lweight + lbph + svi
#Adjusted R-squared:  0.6281
 #   Multiple R-squared:  0.6436

summary(mod5)#- lcp-pgg45-gleason-age- lbph # lpsa ~ lcavol + lweight + svi
#Adjusted R-squared:  0.6242 
 #   Multiple R-squared:  0.6359

summary(mod6) #- lcp-pgg45-gleason-age- lbph - svi #lpsa ~ lcavol + lweight
#Adjusted R-squared:  0.5869
 #   Multiple R-squared:  0.5955

#Из параметра Adjusted R-squared следует что модели 2 и 3 без значений lcp-pgg45-gleason лучше, чем полная модель и другие модели, потому что она имеет более высокое скорректированное значение R-квадрата.

#По мере удаления предикторов значение Multiple R-squared уменьшается. Это показывает что полная модель всегда лучше неполной, но некоторые предикторы могут быть не значимы.

# Таким образом, наилучшей скорректированной моделью является lpsa ~ lcavol + lweight


#Биноминальная модель 

eelModel1 <-glm(formula = svi ~ age, family = binomial(), data = data_E)
exp(eelModel1$coefficients)
exp(confint(eelModel1))


eelModel2 <-glm(formula = svi ~ lpsa + lcavol + lweight + age + lbph + lcp + gleason + pgg45 , family = binomial(), data = data_E)
exp(eelModel2$coefficients)
exp(confint(eelModel2))
summary(eelModel2)
anova(eelModel1, eelModel2)

#Значимыми в полной модели являются такие предикторы как lpsa и lcp

# значение lcp в полинаминальной регрессии мы удалии самой первой из-за низкой значимости по отношению к изучаемой переменной - lpsa.




#модели регрессии Пуассона

eelModel1 <-glm(formula = age ~  lweight + svi + lcp + gleason + pgg45, family = poisson(), data = data_E)
summary(eelModel1)


# переменная lcavol также содержит отрицательные значения поэтому данная модель для рассчета lcavol не подходит

# Однако можно заметить значимую связь между весом простаты и возрастом




#                                  Case F. 



tab <- matrix (c(34, 31, 28, 33, 35, 29, 28), ncol= 7 , byrow= TRUE )
colnames(tab) <- c('Baseline','Week1','Week2','Week3','Week4','Week5','Week6')
tab <- as.table (tab)


library (tseries)
#вычислять автокорреляции
acf(x, pl= FALSE )


#Автокорреляция измеряет степень сходства между временным рядом и его запаздывающей версией в течение последовательных интервалов времени. он измеряет взаимосвязь между текущими значениями переменной и ее историческими значениями.
x <- c(34, 31, 28, 33, 35, 29, 28)
acf(x)
#По оси X отображается количество задержек, а по оси Y — автокорреляция при этом количестве задержек. По умолчанию график начинается с запаздывания = 0, а автокорреляция всегда будет равна 1 при запаздывании = 0.

library(car)
data <- data.frame(score = c(34, 31, 28, 33, 35, 29, 28),week = c(0,1,2,3,4,5,6))

mod <- lm(score ~ week, data = data)

anova(mod)
#F-статистика представляет собой отношение среднеквадратичной обработки к среднеквадратической ошибке
#чем больше F-статистика, тем больше доказательств того, что существует разница между средними группами. В данном случает F value достаточно велико 0.9383 - это значит что существует значимая разница между группами. А так как значение р = 0.3772, больше 0.05/0.1 мы не можем отвергнуть нулевую гипотезу дисперсионного анализа (Н0-средние значения между группами равны). Это означает, что у нас нет достаточных доказательств, чтобы сказать, что существует статистически значимая разница между средними группами.


# Мы не можем сказать что терапия уменьшает уровень беспокойства.

library(ggplot2)
theme_set(theme_bw())
ggplot(data = data, aes(x = week, y = score, colour = week)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)

# Из графиков автокорреляции и распределения значений тревожноси в определенную неделю, можно судить о том что данные мало связаны друг с другом.
